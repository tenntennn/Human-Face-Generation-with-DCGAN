# -*- coding: utf-8 -*-
"""facegeneraation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RqX8PTVZxcOzxJGV2PPYN0ohEyvnI7Vx
"""

from google.colab import drive
drive.flush_and_unmount
drive.mount('/content/drive')

!pip install kaggle

import os
#from genericpath import exists
dataset_dir = '/content/drive/MyDrive/dataset/faces'

os.makedirs(dataset_dir, exist_ok=True)

os.chdir(dataset_dir)
print("Currently working: ", os.getcwd())

print(os.listdir(dataset_dir))

len(os.listdir(dataset_dir))

"""LOADING AND PREPROCESSING DATA"""

!pip install tensorflow

#IMPORT LIBRARIES

import random
from PIL import Image
import numpy as np
import tensorflow as tf
from matplotlib.pylab import plt

import warnings
warnings.filterwarnings('ignore')

#sset parameters of images
img_size = 64
buffer_size= 50000#shuffle image
batch_size = 200

"""DATA PREPROCESSING"""

def load_and_preprocess_image(dataset_dir, imgsize):
  image = []#append preprocced data
  for subdir, _, files in os.walk(dataset_dir):#traverse
    for file in files:
      file_path = os.path.join(subdir, file)
      try:
        img = Image.open(file_path).convert('RGB')
        #resize
        img = img.resize((imgsize, imgsize))
        #float format
        img_array= np.array(img).astype('float32')
        #normalization
        img_array = (img_array-127.5)/127.5
        #aend
        image.append(img_array)
      except Exception as e:
        print(f"Error processing {file_path}: {e}")
  return np.array(image)

images_data = load_and_preprocess_image(dataset_dir, img_size)

len(images_data)

images_data[0].shape#dimension of frist image(.shape for size)

#BATCH AND SHUFFLE THE DATA

train_dataset = tf.data.Dataset.from_tensor_slices(images_data).shuffle(buffer_size).batch(batch_size)#changes to tensorflow dataset

type(train_dataset)

"""2. VISUALIZATION"""

img_files = os.listdir(dataset_dir)[:3]
#create a subplot

fig, axes = plt.subplots(1, 3, figsize=(15, 5))

for i, imgfile in enumerate(img_files):
  img_path = os.path.join(dataset_dir, imgfile)

  #oen image file
  img = Image.open(img_path)

  #display images
  axes[i].imshow(img)
  axes[i].axis('off')

plt.tight_layout()
#plt.show()



"""#3. CREATING MODELS

GENERATOR
"""

latent_dim = 100

def generator_model():
  model = tf.keras.Sequential([
      #dense layer of random nosie
      tf.keras.layers.Dense(8*8*512, input_dim = latent_dim, activation = 'relu'),
      tf.keras.layers.BatchNormalization(),
      tf.keras.layers.Reshape((8, 8, 512)),#conveion to 1d to 3d

      #transpose convolution
      tf.keras.layers.Conv2DTranspose(filters = 256, kernel_size = (4,4), strides = (2, 2), padding = 'same', activation = 'relu'),
      tf.keras.layers.BatchNormalization(),

      tf.keras.layers.Conv2DTranspose(filters = 128, kernel_size = (4,4), strides = (2, 2), padding = 'same', activation = 'relu'),
      tf.keras.layers.BatchNormalization(),

      tf.keras.layers.Conv2DTranspose(filters = 64, kernel_size = (4, 4), strides = (2, 2), padding = 'same', activation = 'relu'),
      tf.keras.layers.BatchNormalization(),

      #otput
      tf.keras.layers.Conv2D(3, kernel_size = (4, 4), padding= 'same', activation= 'tanh')
  ])
  return model

generator = generator_model()
generator.summary()

"""DISCRIMINATOR"""

input = (64, 64, 3)

def discriminator():
  model = tf.keras.Sequential([
      tf.keras.layers.Conv2D(64, kernel_size = (4, 4), strides = (2, 2), padding = 'same', input_shape = input),
      tf.keras.layers.BatchNormalization(),
      tf.keras.layers.LeakyReLU(alpha = 0.2),

      tf.keras.layers.Conv2D(128, kernel_size = (4, 4), strides = (2, 2), padding = 'same'),
      tf.keras.layers.BatchNormalization(),
      tf.keras.layers.LeakyReLU(alpha = 0.2),

      tf.keras.layers.Conv2D(256, kernel_size = (4, 4), strides = (2, 2), padding = 'same'),
      tf.keras.layers.BatchNormalization(),
      tf.keras.layers.LeakyReLU(alpha = 0.2),

      tf.keras.layers.Flatten(),
      tf.keras.layers.Dropout(0.3),

      tf.keras.layers.Dense(1, activation = 'sigmoid')
  ])
  return model

discriminator = discriminator()
discriminator.summary()

"""#4. lOSS FUNCTIONS AND OPTIMIZERS"""

cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits = True)

"""DISCRIMINATOR LOSS"""

def discriminator_loss(real_output, fake_output):
  real_loss = cross_entropy(tf.ones_like(real_output), real_output)
  fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)
  total_loss = real_loss + fake_loss
  return total_loss

"""#GENERATOR LOSS"""

def generator_loss(fake_output):
  return cross_entropy(tf.ones_like(fake_output), fake_output)

"""##OPTIMIZERS"""

generator_optimizer = tf.keras.optimizers.Adam(learning_rate = (1e-4))
discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate = (1e-4))

"""##5. DEFINING TRAINING LOOP"""

epochs = 60
noise_dim = 100
num_examles_to_generate = 8
seed = tf.random.normal([num_examles_to_generate, noise_dim])

"""#TRAINING LOOP"""

@tf.function
def train_step(images):
  noise = tf.random.normal([batch_size, noise_dim])

  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
    generated_image = generator(noise, training = True)

    real_output = discriminator(images, training =True)
    fake_output = discriminator(generated_image, training = True)

    gen_loss = generator_loss(fake_output)
    disc_loss = discriminator_loss(real_output, fake_output)

  gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)
  gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)

  generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))
  discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))

"""STORE GENERATED IMAGES"""

def generate_and_save(model, epoch, test_input):
  predictions = model(test_input, training = False)
  predictions = (predictions+1)/2.0

  save_dir = "/content/drive/My Drive/generated_images"  # ✅ Directory to save images
  os.makedirs(save_dir, exist_ok=True)

  fig = plt.figure(figsize=(4,4))

  for i in range(predictions.shape[0]):
    plt.subplot(4, 4, i+1)
    plt.imshow(predictions[i])
    plt.axis('off')

  plt.savefig('/content/drive/My Drive/generated_images/image_at_epoch_{:04d}.png'.format(epoch))
  plt.close()

def train(dataset, epochs):
  for epoch in range(epochs):
    print(f"Starting epoch{epoch + 1}/{epochs}")

    for image_batch in dataset:
      train_step(image_batch)
    generate_and_save(generator, epoch + 1, seed)

#train(train_dataset, epochs)

image_folder = '/content/drive/My Drive/generated_images'
image_path = [os.path.join(image_folder, file) for file in os.listdir(image_folder) if file.endswith('.png')]
random_images = random.sample(image_path, 3)
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

for ax, img_path in zip(axes, random_images):
  img = Image.open(img_path)
  ax.imshow(img)
  ax.axis('off')

plt.tight_layout()

!pip install imagehash

img = Image.open("/content/drive/My Drive/generated_images/image_at_epoch_0060.png").convert("RGB")
print(img.size)

import numpy as np
from PIL import Image

def detect_image_gaps_and_margins(image_path):
    img = Image.open(image_path).convert("L")  # convert to grayscale
    arr = np.array(img)

    # Threshold to treat nearly white as blank
    threshold = 250

    # Create a binary map: 1 if pixel is below threshold (i.e., not white), else 0
    binary = (arr < threshold).astype(np.uint8)

    # Sum along rows and columns to detect active areas
    vertical_profile = binary.sum(axis=1)  # horizontal lines
    horizontal_profile = binary.sum(axis=0)  # vertical lines

    # Detect top and bottom margins
    top_margin = np.argmax(vertical_profile > 0)
    bottom_margin = len(vertical_profile) - np.argmax(vertical_profile[::-1] > 0) - 1

    # Detect left and right margins
    left_margin = np.argmax(horizontal_profile > 0)
    right_margin = len(horizontal_profile) - np.argmax(horizontal_profile[::-1] > 0) - 1

    # Detect vertical gaps (between rows of tiles)
    vertical_gaps = []
    prev = top_margin
    for i in range(top_margin + 1, bottom_margin):
        if vertical_profile[i] == 0 and vertical_profile[i - 1] > 0:
            start = i
        if vertical_profile[i] > 0 and vertical_profile[i - 1] == 0:
            end = i
            gap = end - start
            vertical_gaps.append(gap)

    # Detect horizontal gaps (between columns of tiles)
    horizontal_gaps = []
    for i in range(left_margin + 1, right_margin):
        if horizontal_profile[i] == 0 and horizontal_profile[i - 1] > 0:
            start = i
        if horizontal_profile[i] > 0 and horizontal_profile[i - 1] == 0:
            end = i
            gap = end - start
            horizontal_gaps.append(gap)

    # Print results
    print(f"Top margin: {top_margin} pixels")
    print(f"Bottom margin: {img.height - bottom_margin - 1} pixels")
    print(f"Left margin: {left_margin} pixels")
    print(f"Right margin: {img.width - right_margin - 1} pixels")

    if vertical_gaps:
        print(f"Estimated vertical gap(s): {set(vertical_gaps)} pixels")
    else:
        print("No vertical gaps detected")

    if horizontal_gaps:
        print(f"Estimated horizontal gap(s): {set(horizontal_gaps)} pixels")
    else:
        print("No horizontal gaps detected")

# Example usage
detect_image_gaps_and_margins("/content/drive/My Drive/generated_images/image_at_epoch_0001.png")

import os
from PIL import Image

# Paths
input_folder = "/content/drive/My Drive/generated_images"
output_base = "/content/drive/My Drive/split_tiles"

# Grid + layout config
grid_size = (4, 4)
tile_size = 64  # final size you want
# These were measured before:
left_margin = 50
top_margin = 48
right_margin = 40
bottom_margin = 44
horizontal_gap = 14
vertical_gap = 13

# Process all grid images
for filename in sorted(os.listdir(input_folder)):
    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):
        print(f"Processing {filename}")
        img_path = os.path.join(input_folder, filename)
        img = Image.open(img_path).convert("RGB")

        # Create output folder for this image
        image_folder = os.path.join(output_base, filename.split('.')[0])
        os.makedirs(image_folder, exist_ok=True)

        # Split into tiles
        for row in range(grid_size[1]):
            for col in range(grid_size[0]):
                left = left_margin + col * ( (img.width - left_margin - right_margin - (grid_size[0]-1)*horizontal_gap) // grid_size[0] + horizontal_gap )
                upper = top_margin + row * ( (img.height - top_margin - bottom_margin - (grid_size[1]-1)*vertical_gap) // grid_size[1] + vertical_gap )
                right = left + ( (img.width - left_margin - right_margin - (grid_size[0]-1)*horizontal_gap) // grid_size[0] )
                lower = upper + ( (img.height - top_margin - bottom_margin - (grid_size[1]-1)*vertical_gap) // grid_size[1] )

                tile = img.crop((left, upper, right, lower)).resize((tile_size, tile_size))
                tile.save(os.path.join(image_folder, f"tile_{row * grid_size[0] + col}.png"))

import os
from PIL import Image
import imagehash

# Paths
real_folder = "/content/drive/My Drive/orl_faces/faces"
generated_tiles_base = "/content/drive/My Drive/split_tiles"

# Similarity threshold
threshold = 5

# Load and hash real images
real_hashes = []
for filename in os.listdir(real_folder):
    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):
        img = Image.open(os.path.join(real_folder, filename)).convert('RGB').resize((64, 64))
        img_hash = imagehash.phash(img)
        real_hashes.append((filename, img_hash))

print(f"Loaded and hashed {len(real_hashes)} real images.\n")

# Check each generated tile in each epoch folder
for epoch_folder in sorted(os.listdir(generated_tiles_base)):
    epoch_path = os.path.join(generated_tiles_base, epoch_folder)
    if not os.path.isdir(epoch_path):
        continue

    for tile_filename in sorted(os.listdir(epoch_path)):
        if tile_filename.lower().endswith(('.png', '.jpg', '.jpeg')):
            tile_path = os.path.join(epoch_path, tile_filename)
            tile_img = Image.open(tile_path).convert('RGB').resize((64, 64))
            tile_hash = imagehash.phash(tile_img)

            match_found = False
            for real_filename, real_hash in real_hashes:
                distance = tile_hash - real_hash
                if distance <= threshold:
                    print(f"✅ SIMILAR (distance {distance}) → Epoch [{epoch_folder}], Tile [{tile_filename}] ≈ Real [{real_filename}]")
                    match_found = True
                    break

            if not match_found:
                print(f"❌ NO SIMILARITY → Epoch [{epoch_folder}], Tile [{tile_filename}]")

import os
from PIL import Image
import matplotlib.pyplot as plt

# Paths to tile folders
tiles_root = "/content/drive/My Drive/split_tiles"
epoch1_dir = os.path.join(tiles_root, "image_at_epoch_0001")
epoch60_dir = os.path.join(tiles_root, "image_at_epoch_0060")

# Load up to 16 tiles from each epoch
epoch1_tiles = sorted([os.path.join(epoch1_dir, f) for f in os.listdir(epoch1_dir) if f.endswith('.png')])[:16]
epoch60_tiles = sorted([os.path.join(epoch60_dir, f) for f in os.listdir(epoch60_dir) if f.endswith('.png')])[:16]

# Display tiles in two rows (Epoch 1 and Epoch 60)
fig, axes = plt.subplots(2, 16, figsize=(20, 3))

for i in range(16):
    # Epoch 1
    img1 = Image.open(epoch1_tiles[i])
    axes[0, i].imshow(img1)
    axes[0, i].axis('off')
    if i == 7:
        axes[0, i].set_title("Epoch 1")

    # Epoch 60
    img60 = Image.open(epoch60_tiles[i])
    axes[1, i].imshow(img60)
    axes[1, i].axis('off')
    if i == 7:
        axes[1, i].set_title("Epoch 60")

plt.tight_layout()
plt.show()